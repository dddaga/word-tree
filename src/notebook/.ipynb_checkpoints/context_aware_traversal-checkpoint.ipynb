{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "DB= config.DB\n",
    "CONTEXT_DIMENSION = 128\n",
    "\n",
    "\n",
    "if DB == 'MONGO':\n",
    "    from src.utilities.graph_operations.mongodb import touch_connection_db, find_word, update_graph_context\n",
    "if DB == 'REDIS':\n",
    "    from src.utilities.graph_operations.redis import touch_connection_db, find_word, update_graph_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDIS\n"
     ]
    }
   ],
   "source": [
    "print(config.DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_input_context(text):\n",
    "    running_context = np.zeros(CONTEXT_DIMENSION)\n",
    "    words = text.split(' ')\n",
    "    connections = get_ngram(words,2)\n",
    "    for connection in connections:\n",
    "        connection_properties = touch_connection_db(connection[0],connection[1])\n",
    "        if connection_properties['update_count'] == 0:\n",
    "            print('connection is not trained,' ,connection)\n",
    "        running_context += connection_properties['context']\n",
    "        running_context = running_context / np.linalg.norm(running_context)\n",
    "        \n",
    "    return running_context, connection[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_node_activations(word,running_context,breadth):\n",
    "   \n",
    "    word_connections = find_word(word)\n",
    "    \n",
    "    if len(word_connections) >0 :\n",
    "\n",
    "        breadth = min(len(word_connections),breadth)\n",
    "        words, activation_socre, connection_context =  get_context_agreement(word_connections,running_context)\n",
    "       \n",
    "        #get index of max n \n",
    "        active_index = np.argpartition(activation_socre,-breadth)[-breadth:]\n",
    "        activation_socre   = [ activation_socre[i] for i in active_index]\n",
    "        connections        = [ words[i] for i in active_index]\n",
    "        connection_context = [ connection_context[i] for i in active_index]\n",
    "\n",
    "        return activation_socre,connection_context,connections \n",
    "\n",
    "    else :\n",
    "        print('graph has no connections for the word {}'.format(word))\n",
    "        return [] , [] ,[]\n",
    "    \n",
    "def get_branch_activations(text,breadth,depth) :\n",
    "    \n",
    "    running_context, origin = get_input_context(text)\n",
    "    # [['word'] ,score, running_context,  , depth]\n",
    "    response =  [[[origin] , 0 ,running_context, 0]]\n",
    "    output   = []\n",
    "    while len(response) > 0 : \n",
    "        if response[0][3] < depth:\n",
    "            shifted_origin = response[0][0][-1]\n",
    "            shited_context = response[0][2]\n",
    "            activation_score,connection_context ,connections = get_node_activations(shifted_origin,shited_context,breadth)\n",
    "            p_node = response[0].copy()\n",
    "            response.pop(0)\n",
    "            for index, connection in enumerate(connections):\n",
    "                branch  = p_node[0] + [connection]\n",
    "                context = connection_context[index]\n",
    "                score   = p_node[1] + activation_score[index]\n",
    "                level   = p_node[3] + 1\n",
    "                response.append([branch , score,context ,level])\n",
    "        else :\n",
    "            response[0][0].pop(0)\n",
    "            output.append(response[0][:-2])\n",
    "            response.pop(0)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def get_context_agreement(word_connections,running_context):\n",
    "    words = []\n",
    "    activation_socre =[]\n",
    "    connection_context =[]\n",
    "    for connection in word_connections :\n",
    "        context  = connection['context']\n",
    "        activation_socre.append(np.dot(running_context,context))\n",
    "        words.append(connection['connection'])\n",
    "        connection_context.append(enrich_context(running_context,context))\n",
    "        \n",
    "    return words, activation_socre, connection_context\n",
    "        \n",
    "\n",
    "def enrich_context(running_context,connection_context):\n",
    "    \n",
    "    enriched_context_vector  = running_context + connection_context\n",
    "    \n",
    "    return enriched_context_vector / np.linalg.norm(enriched_context_vector)\n",
    "\n",
    "\n",
    "def get_ngram(indices, window_size=2):\n",
    "    ngrams = []\n",
    "    count = 0\n",
    "    for token in indices[:len(indices)-window_size+1]:\n",
    "        ngrams.append(indices[count:count+window_size])\n",
    "        count = count+1\n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection is not trained, ['why', 'are']\n",
      "connection is not trained, ['you', 'here']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['three', 'four'], -0.3946688553482317],\n",
       " [['three', 'tospoviruses'], -0.393924224407825],\n",
       " [['three', 'final'], -0.3844948314769563],\n",
       " [['three', 'shoulder'], -0.3839038988057706],\n",
       " [['three', 'at'], -0.29003624678266415],\n",
       " [['three', 'values'], -0.38913198895883483],\n",
       " [['three', 'nominations'], -0.38832181237071617],\n",
       " [['three', 'hog'], -0.369149968402271],\n",
       " [['three', 'folded'], -0.3724995262068898],\n",
       " [['three', 'months'], -0.38307064363922594],\n",
       " [['three', 'wickets'], -0.35255792548515086],\n",
       " [['three', 'prominent'], -0.3877980749806179],\n",
       " [['three', 'are'], -0.3357012461900506],\n",
       " [['three', 'added'], -0.3920757053755061],\n",
       " [['three', 'positions'], -0.3790851264906019],\n",
       " [['these', 'risks'], -0.39984797179050474],\n",
       " [['these', 'years'], -0.39931300222833455],\n",
       " [['these', 'tournaments'], -0.3922874373840285],\n",
       " [['these', 'historical'], -0.39879735422263257],\n",
       " [['these', 'being'], -0.39878479789832744],\n",
       " [['these', 'results'], -0.3993625060363567],\n",
       " [['these', 'same'], -0.39598146351000496],\n",
       " [['these', 'corregidores'], -0.39056632037577943],\n",
       " [['these', 'concerns'], -0.39005411716095595],\n",
       " [['these', 'involving'], -0.38868764247332743],\n",
       " [['these', 'conditions'], -0.3848401304055925],\n",
       " [['these', 'animals'], -0.32855492498927946],\n",
       " [['these', 'regions'], -0.3835627004495148],\n",
       " [['these', 'territories'], -0.3566631332114847],\n",
       " [['these', 'classroom'], -0.3318354949540498],\n",
       " [['cassiopeia', 'from'], -0.5945680721100738],\n",
       " [['vaughn', 'as'], -0.4383430543104183],\n",
       " [['vaughn', 'hit'], -0.436364171343193],\n",
       " [['vaughn', 'background'], -0.4329542128431228],\n",
       " [['vaughn', 'left'], -0.38886930926298496],\n",
       " [['vaughn', 'most'], -0.4306677130511529],\n",
       " [['vaughn', 'to'], -0.40582840800161857],\n",
       " [['vaughn', 'is'], -0.41704145500128303],\n",
       " [['vaughn', 'that'], -0.39110778864375817],\n",
       " [['vaughn', 'here'], -0.3341720760433812],\n",
       " [['vaughn', 'answered'], -0.32879213510280947],\n",
       " [['vaughn', 'had'], -0.40016797486590894],\n",
       " [['vaughn', 'met'], -0.37120390528321645],\n",
       " [['vaughn', 'and'], -0.42285548924045624],\n",
       " [['vaughn', 'the'], -0.4135760592321892],\n",
       " [['vaughn', 'jack'], -0.3983050870387559],\n",
       " [['to', 'sunshine'], -0.3716499849939497],\n",
       " [['to', 'kortlandt'], -0.37124806816937916],\n",
       " [['to', 'northampton'], -0.361968217178991],\n",
       " [['to', 'disorientation'], -0.3522434833664957],\n",
       " [['to', 'few'], -0.3537208202908527],\n",
       " [['to', 'name'], -0.35120084752067954],\n",
       " [['to', 'dementia'], -0.34949566793648323],\n",
       " [['to', 'utopia'], -0.3206990921897962],\n",
       " [['to', 'incapacitate'], -0.33838699741206846],\n",
       " [['to', 'review'], -0.34113973583168855],\n",
       " [['to', 'test'], -0.3478026251888486],\n",
       " [['to', 'portsmouth'], -0.3295862836190331],\n",
       " [['to', 'focus'], -0.34194099897481717],\n",
       " [['to', 'compare'], -0.2683252797739203],\n",
       " [['to', 'gilchrist'], -0.3318078594188476],\n",
       " [['together', 'not'], -0.44927152009840676],\n",
       " [['together', 'the'], -0.44815595528872504],\n",
       " [['together', 'impact'], -0.44583068863410097],\n",
       " [['together', 'will'], -0.4467811759798129],\n",
       " [['together', 'by'], -0.44002922285095414],\n",
       " [['together', 'were'], -0.4356948658310073],\n",
       " [['together', 'band'], -0.337244169668519],\n",
       " [['together', 'strips'], -0.37138715681034207],\n",
       " [['together', 'single'], -0.4382179677719552],\n",
       " [['together', 'views'], -0.429709110845441],\n",
       " [['together', 'all'], -0.3984723008199734],\n",
       " [['together', 'she'], -0.43101945141232767],\n",
       " [['together', 'as'], -0.4181082900197562],\n",
       " [['together', 'through'], -0.42638634644823775],\n",
       " [['together', 'students'], -0.4359759295423059],\n",
       " [['rippel', 'my'], -0.6015859430538653],\n",
       " [['wolfe', 'read'], -0.531586947668777],\n",
       " [['wolfe', 'provides'], -0.5271522775283559],\n",
       " [['wolfe', 'thesis'], -0.520116029165639],\n",
       " [['wolfe', 'said'], -0.5119130589809266],\n",
       " [['wolfe', 'previous'], -0.4734672274025131],\n",
       " [['wolfe', 'concluded'], -0.46804328559376307],\n",
       " [['wolfe', 'set'], -0.5163976307376026],\n",
       " [['wolfe', 'agility'], -0.48402980888066055],\n",
       " [['wolfe', 'longtime'], -0.48813707460244793],\n",
       " [['wolfe', 'criticized'], -0.5178311727375561],\n",
       " [['wolfe', 'critique'], -0.4988231584412774],\n",
       " [['wolfe', 'other'], -0.44857343300915775],\n",
       " [['wolfe', 'praised'], -0.49697262034263007],\n",
       " [['wolfe', 'did'], -0.4243514992705498],\n",
       " [['wolfe', 'fascist'], -0.47637532526484505],\n",
       " [['blackburn', 'north'], -0.6898426290512669],\n",
       " [['blackburn', 'cc'], -0.5660455976985693],\n",
       " [['blackburn', 'rovers'], -0.6297334496855919],\n",
       " [['blackburn', 'goalposts'], -0.5216354864988622],\n",
       " [['blackburn', 'bob'], -0.5713307069655441],\n",
       " [['blackburn', 'olympic'], -0.3967410183444601],\n",
       " [['blackburn', 'new'], -0.5289025193801815],\n",
       " [['blackburn', 'and'], -0.5936734301045129],\n",
       " [['in', 'venezuela'], -0.41368958086765456],\n",
       " [['in', 'drug'], -0.4094479058500589],\n",
       " [['in', 'ruginoasa'], -0.4053752684731964],\n",
       " [['in', 'serious'], -0.4037350814008661],\n",
       " [['in', 'children'], -0.3817966282720065],\n",
       " [['in', 'successful'], -0.30201857450183955],\n",
       " [['in', 'activities'], -0.3751108290769939],\n",
       " [['in', 'anthony'], -0.39448311415283527],\n",
       " [['in', 'misdiagnosis'], -0.40042347270038564],\n",
       " [['in', 'prior'], -0.3776734771201847],\n",
       " [['in', 'african'], -0.3908914863396643],\n",
       " [['in', 'limited'], -0.39876941051702064],\n",
       " [['in', 'discography'], -0.3317757842194663],\n",
       " [['in', 'interesting'], -0.36325225017945384],\n",
       " [['in', 'fall'], -0.3712765148511992],\n",
       " [['carlisle', 'drums'], -0.6906992969637583],\n",
       " [['carlisle', 'cc'], -0.4905036221793645],\n",
       " [['carlisle', 'north'], -0.4489921189854749],\n",
       " [['carlisle', 'circus'], -0.6902355629254069],\n",
       " [['carlisle', 'born'], -0.6323359403593016],\n",
       " [['carlisle', 'crown'], -0.5478742136911271],\n",
       " [['carlisle', 'and'], -0.38080592739210645],\n",
       " [['carlisle', 'railway'], -0.607197155381327],\n",
       " [['carlisle', 'guitar'], -0.5812851518771857],\n",
       " [['they', 'might'], -0.5761796760305891],\n",
       " [['they', 'further'], -0.5760689513136815],\n",
       " [['they', 'should'], -0.5746647722003762],\n",
       " [['they', 'usually'], -0.45548827426626004],\n",
       " [['they', 'include'], -0.5357173130477497],\n",
       " [['they', 'shot'], -0.5429429180171131],\n",
       " [['they', 'stated'], -0.4110622279646893],\n",
       " [['they', 'then'], -0.4336777291545347],\n",
       " [['they', 'sampled'], -0.49878361317890824],\n",
       " [['they', 'close'], -0.40817961030048316],\n",
       " [['they', 'adopt'], -0.5617289126261402],\n",
       " [['they', 'weren'], -0.5680963843066074],\n",
       " [['they', 'also'], -0.5639049046509524],\n",
       " [['they', 'subjugated'], -0.5737634820202873],\n",
       " [['they', 'get'], -0.5301325135837327],\n",
       " [['chesterfield', 'midlands'], -0.6753359915164862],\n",
       " [['as', 'wire'], -0.3518847103490909],\n",
       " [['as', 'liberty'], -0.3514074434437461],\n",
       " [['as', 'peter'], -0.3508084709692277],\n",
       " [['as', 'thomas'], -0.35041487574895586],\n",
       " [['as', 'kevin'], -0.3250169061228313],\n",
       " [['as', 'competitions'], -0.3265631576842779],\n",
       " [['as', 'enduring'], -0.33736772209120613],\n",
       " [['as', 'hugh'], -0.29939725429525704],\n",
       " [['as', 'pianist'], -0.3466063434313698],\n",
       " [['as', 'journalist'], -0.33521876798415795],\n",
       " [['as', 'troop'], -0.34361498065708873],\n",
       " [['as', 'company'], -0.34473087366890887],\n",
       " [['as', 'can'], -0.3249498801161975],\n",
       " [['as', 'credible'], -0.34938018468773935],\n",
       " [['as', 'gretham'], -0.33233216727269543],\n",
       " [['was', 'staff'], -0.40637763212817424],\n",
       " [['was', 'belgian'], -0.4045847084899721],\n",
       " [['was', 'against'], -0.3986124033872104],\n",
       " [['was', 'terminated'], -0.38441490105613535],\n",
       " [['was', 'chinese'], -0.3926991858085428],\n",
       " [['was', 'mirrored'], -0.37551399165138966],\n",
       " [['was', 'needed'], -0.40195676802899044],\n",
       " [['was', 'two'], -0.3822876775421513],\n",
       " [['was', 'diplomat'], -0.38033010957199026],\n",
       " [['was', 'liu'], -0.40095757531943077],\n",
       " [['was', 'critically'], -0.39211723094709433],\n",
       " [['was', 'particularly'], -0.367604879152266],\n",
       " [['was', 'edmund'], -0.29866077284853154],\n",
       " [['was', 'likely'], -0.2762477338695324],\n",
       " [['was', 'romanian'], -0.32617484356348975]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth =  2\n",
    "breadth =15\n",
    "text = 'why are you here'\n",
    "get_branch_activations(text,breadth,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anuvaad",
   "language": "python",
   "name": "anuvaad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
